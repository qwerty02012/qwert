import tensorflow as tf
import numpy as np
from numpy.linalg import eig
//Creating Matrix A & B
A=np.arange(1,5).reshape(2,2)
B=np.arange(5,9).reshape(2,2)
//Multiplying A & B
C=tf.matmul(A,B)
//Getting Eigen Values and Vectors
eigen_values_C,eigen_vectors_C= eig(C)
print(eigen_values_C)
print(eigen_vectors_C)








import numpy as np
from keras.models import Sequential
from keras.layers.core import Dense
print("Sahil Gurnani MLDC 06")
input_data = np.array([[0,0],[0,1],[1,0],[1,1]])
target_data = np.array([[0],[1],[1],[0]])
model = Sequential()
model.add(Dense(8, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy',
optimizer='adam',
metrics=['binary_accuracy'])
model.fit(input_data, target_data, epochs=300, verbose=1)
print(model.predict(input_data).round())










from keras.datasets import mnist 
from keras.models import Sequential 
from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten
from keras.utils import np_utils
# to calculate accuracy 
from sklearn.metrics import accuracy_score
#to visualize data
import matplotlib.pyplot as plt# loading the dataset
(X_train, y_train), (X_test, y_test) = mnist.load_data() 
# building the input vector from the 28x28 pixels
X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)
X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
# normalizing the data to help with the training
X_train /= 255
X_test /= 255
# one-hot encoding using keras' numpy-related utilities
n_classes = 10

print("Shape before one-hot encoding: ", y_train.shape)
Y_train = np_utils.to_categorical(y_train, n_classes) 
Y_test = np_utils.to_categorical(y_test, n_classes)
print("Shape after one-hot encoding: ", Y_train.shape) 
# building a linear stack of layers with the sequential model
model = Sequential() # convolutional layer
model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))
model.add(MaxPool2D(pool_size=(1,1)))
# flatten output of conv
model.add(Flatten()) 
# hidden layer
model.add(Dense(100, activation='relu'))
# output layer
model.add(Dense(10, activation='softmax')) 
# compiling the sequential model
model.compile(loss= 'categorical_crossentropy', metrics =['accuracy'], optimizer='adam')

# training the model for 10 epochs 
model.fit(X_train, Y_train, batch_size=128, epochs=2, validation_data=(X_test, Y_test)) 
image_index = 225  #index of the image you want to predict.
plt.imshow(X_test[image_index].reshape(28, 28), cmap= 'Greys')  #plot the image with specified index.
predict = X_test[image_index].reshape(28, 28)  #reshape the image data to 28x28.
pred = model.predict(X_test[image_index].reshape(1, 28, 28, 1)) #predic the digit in image using the trained model
print("Predicted No: ", pred.argmax()) #print the prediction.


















Binary

# Load libraries
import numpy as np
from keras.datasets import imdb
from keras.preprocessing.text import Tokenizer
from keras import models
from keras import layers

# Set random seed
np.random.seed(0)
# Set the number of features we want
number_of_features = 1000

# Load data and target vector from movie review data
(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features)

# Convert movie review data to one-hot encoded feature matrix
tokenizer = Tokenizer(num_words=number_of_features)
train_features = tokenizer.sequences_to_matrix(train_data, mode='binary')
test_features = tokenizer.sequences_to_matrix(test_data, mode='binary')
# Start neural network
network = models.Sequential()

# Add fully connected layer with a ReLU activation function
network.add(layers.Dense(units=16, activation='relu', input_shape=(number_of_features,)))

# Add fully connected layer with a ReLU activation function
network.add(layers.Dense(units=16, activation='relu'))

# Add fully connected layer with a sigmoid activation function
network.add(layers.Dense(units=1, activation='sigmoid'))

# Compile neural network
network.compile(loss='binary_crossentropy', # Cross-entropy
                optimizer='rmsprop', # Root Mean Square Propagation
                metrics=['accuracy']) # Accuracy performance metric

# Train neural network
history = network.fit(train_features, # Features
                      train_target, # Target vector
                      epochs=3, # Number of epochs
                      verbose=1, # Print description after each epoch
                      batch_size=100, # Number of observations per batch
                      validation_data=(test_features, test_target)) # Data for evaluation

